\chapter{Related Work}
\label{chap:related}
This area of research is becoming more and more popular in recent years with more and more publications in top conferences such as NIPS and POPL, attracting researchers from universities such as MIT and Stanford and industry research institutions such as Microsoft Research. However, to our best knowledge, this area has not even been studied in China. 

In this chapter, we will introduce the state of the art probabilistic programming languages and systems, algorithms of inference engine, as well as the current problems existed for probabilistic programming.

\section{Probabilistic Languages for Machine Learning}
We have evaluated the existing probabilistic programming systems including BUGS, Church, FACTORIE, Infer.NET, Dimple, etc. More specifically, BUGS~\cite{bugs} is a language for specifying finite graphical models and accompanying software for performing Bayesian inference Using Gibbs Sampling. Church~\cite{church} is a universal probabilistic programming language, extending Scheme with probabilistic semantics, and is well suited for describing infinite-dimensional stochastic processes and other recursively-defined generative processes. Factorie~\cite{factorie} is a Scala library for creating relational factor graphs, estimating parameters and performing inference. Infer.NET~\cite{infernet} is a software library developed by Microsoft for expressing graphical models and implementing Bayesian inference using a variety of algorithms within the .NET platform. Dimple~\cite{dimple} is a software tool that performs inference and learning on probabilistic graphical models via belief propagation algorithms or sampling based algorithms. IBAL~\cite{ibal} is a rational programming language for probabilistic and decision-theoretic agents. It also also integrates Bayesian parameter estimation and decisiontheoretic utility maximization thoroughly into the framework. But it only works with discrete data types. Alchemy ~\cite{alchemy} represents Markov logic networks, and undirected graphical model over log-linear-weighted first order logic, which is inherentedly discrete. In summary, all these probabilistic programming languages are extended from a domain language and each of them inherits the same syntax and the data types of the domain language.

\subsection{BUGS}
The BUGS (Bayesian inference Using Gibbs Sampling) project is concerned with flexible software for the Bayesian analysis of complex statistical models using Markov chain Monte Carlo (MCMC) methods.\cite{bugs}. BUGS allow users to specify a generative model imperatively, then it does inference with a Gibbs sampler, thus being able to handle a wide variety of different sorts of models. BUGS can also be used from R. Actually, the model definition language in BUGS itself is R-like but not actually R. BUGS is not a Turing-complete language.

\subsection{Infer.NET}
Infer.NET focuses on message-passing inference~\cite{bishop}, written in C\#. It has a visualized representation of the declared probabilistic grphical models to help the users to check correctness. If offers several options of inference algorithms including both exact inference and approximate inference. Users can only use Infer.NET in the .NET framework.

\subsection{Church}
Church extends (the purely functional subset of) Scheme with elementary random primitives(ERP), such as flip (a bernoulli), multinomial, and gaussian. In addition, Church includes language constructs that simplify modeling. For instance, mem, a higher-order procedure that memoizes its input function, is useful for describing persistent random properties and lazy model construction. (Interstingly, memoization has a semantic effect in probabilistic languages.) If we view the semantics of the underlying deterministic language as a map from programs to executions of the program, the semantics of the probabilistic language will be a map from programs to distributions over executions. When the program halts with probability one, this induces a proper distribution over return values. Indeed, any computable distribution can be represented as the distribution induced by a Church program in this way(see ~\cite{goodman}, ~\cite{church}).

\subsection{FACTORIE}
\textit{Factorie}~\cite{factorie} focuses on factor graphs and discriminative undirected models. They implemented a library for Scala to allow sampling from probabilistic distributions and inference automatically. Factorie has good scalability over large parameters in the probabilistic graphical models. Different from previous probabilistic programming languages, it targets Markov networks rather than Bayesian networks.

\section{Lightweight Implementation of Probabilistic Programming Language}
~\cite{lightweight} propopsed a general method for transforming arbitrary programming languages into probabilistic programming languages with an accompanying implementation of staightforward Markov chain Monte Carlo inference engines. Their maim contribution lies in the naming strategy that they give each random choice of a fixed program a unique ``name'' depending on the position of in a given execution trace. Such that the stochastic functions can be converted into deterministic ones as the names can be used to look up the return value in a database that stores the values of all the random choices in a fixed program. ~\cite{nonstandard} showed how \textit{nonstandard interpretations} of probabilistic programs can be used to perform efficient inference algorithms. In their method, infromation about the structure of the distributions (which is the dependencies or gradients in the probabilistic graphical models) is derived as monad-like side computation as the same time of executing the program. Meanwhile, the interpreations can be coded easily with some special-purpose objects and operator overloading. They promoted the inference efficiency perfomance by using the structure information of distribution as part of the variety of infreence algorithms.

Additionally, because of the program is in a machine-readable form, various of techniques from compiler design and program analysis can be used in the inference engine. ~\cite{gordon2013} designed a new model-learner pattern for Bayesian reasoning. In their work, a new probabilistic programming abstraction was proposed, a typed Bayesian model, based on a pair of probabilistic expressions for the prior and sampling distributions. Also, ~\cite{dataflow} presented a new algorithm for Bayesian inference over probabilistic programs, whihc is based on data flow analysis techniques from the program analysis community.

\section{Problem}
\label{sec:prob}

Although currently there are many probabilistic programming languages and systems, as stated above, the problem is that this is not easy for those cross-platform developments where they have to get accustomed to the different kinds of probabilistic programming languages or libraries. Henceforth, what we proposed is the Portable Probabilistic Programming Framework that can be embedded in every programming language people commonly used.

We designed the syntax for the portable probabilistic programming language which targets Bayesian networks and conditional query. The design of the language is based on BUGS and is more specific and efficient for describing the probabilistic models. The description of the models using the portable probabilistic programming language is separated from the code of the host language as well of the conditional query, which can enhance the reusability of the probabilistic models. The parser is implemented and the inference engine is generated automatically based on the conditional query. The inference algorithm is based on the MCMC sampling, such as Gibbs Sampling or Metropolis-Hastings Algorithm, which is efficient and lightweight to implement. Additionally, the APIs for other languages is attached leveraging some existing development tool such as SWIG (Simplified Wrapper and Interface Generator). 

Our main contribution lies in the design of the portable probabilistic programming language to make it portable, the implementation of the probabilistic library and the lightweight implementation of the inference engine. 